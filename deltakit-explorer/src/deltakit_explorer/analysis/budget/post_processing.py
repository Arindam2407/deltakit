from collections.abc import Mapping, Sequence

import numpy
import numpy.typing as npt
import pandas

from deltakit_explorer.analysis._analysis import (
    calculate_lambda_and_lambda_stddev,
    compute_logical_error_per_round,
)


def compute_lambda_and_stddev_from_results(
    xi: npt.NDArray[numpy.float64],
    num_rounds_by_distance: Mapping[int, Sequence[int]],
    data: pandas.DataFrame,
) -> tuple[npt.NDArray[numpy.float64], npt.NDArray[numpy.float64]]:
    """Compute Λ from ``data`` for all the provided noise parameters in ``xi``.

    This function assumes that the provided ``data`` has been generated with
    ``RunAllAnalysisEngine`` and the tasks returned by
    ``generate_decoder_managers_for_lambda`` called on the exact same parameters as
    provided here.

    Args:
        xi (npt.NDArray[numpy.float64]): an array of shape ``(m, n)``, where ``m`` is
            the number of noise parameters needed by ``noise_model_type`` and ``n`` the
            number of points to evaluate Λ on.
        num_rounds_by_distances (Mapping[int, Sequence[int]]): the different number of
            rounds that will be used to estimate the logical error-rate per round for
            each code distance. As a rule of thumb, at least ``4`` entries should be
            provided and the maximum number of rounds should, if possible, give a
            logical error-rate above ``0.2`` for the largest distance and a logical
            error-rate below ``0.45`` for the smallest distance. You will not be able to
            check those thresholds everytime, but the standard errors computed will be
            lower if they are verified.
        data (pandas.DataFrame): data generated by executing ``RunAllAnalysisEngine`` on
            the tasks returned by ``generate_decoder_managers_for_lambda`` called
            with the exact same parameters as provided to this function.

    Returns:
        two arrays of dimensions ``(1, n)``. The first array contains an estimation of Λ
        for each parameters in ``xi`` and the second array contains the computed
        standard deviations.
    """
    if len(xi.shape) != 2:
        raise ValueError(f"Expected a 2-dimensional array but got shape {xi.shape}.")
    _, n = xi.shape
    ret: npt.NDArray[numpy.float64] = numpy.zeros((1, n), dtype=numpy.float64)
    stddev: npt.NDArray[numpy.float64] = numpy.zeros_like(ret)
    for i in range(n):
        df = data[data["noise_parameters"].apply(lambda x: numpy.allclose(x, xi[:, i]))]
        lambda_, lambda_stddev = _compute_lambda_from_results(num_rounds_by_distance, df)
        ret[0, i], stddev[0, i] = lambda_, lambda_stddev
    return ret, stddev


def _compute_lambda_from_results(
    num_rounds_by_distance: Mapping[int, Sequence[int]],
    data: pandas.DataFrame,
) -> tuple[float, float]:
    lerprs: list[float] = []
    lerpr_stddevs: list[float] = []
    distances = sorted(num_rounds_by_distance.keys())
    for d in distances:
        df = data[data["distance"] == d]
        lerpr, lerpr_stddev = _compute_logical_error_rate_per_round_from_results(
            num_rounds_by_distance[d], df
        )
        lerprs.append(lerpr)
        lerpr_stddevs.append(lerpr_stddev)
    return calculate_lambda_and_lambda_stddev(distances, lerprs, lerpr_stddevs)


def _compute_logical_error_rate_per_round_from_results(
    num_rounds: Sequence[int], data: pandas.DataFrame
) -> tuple[float, float]:
    num_fails: list[int] = []
    num_shots: list[int] = []
    for nrounds in num_rounds:
        data_row = data.query(f"num_rounds == {nrounds}")
        nfails = data_row["fails"].values[0]
        nshots = data_row["shots"].values[0]
        num_fails.append(nfails)
        num_shots.append(nshots)
    return compute_logical_error_per_round(num_fails, num_shots, num_rounds)
